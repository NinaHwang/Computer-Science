# 4. Thread Concurrency and Deadlocks

Created: December 19, 2021 8:33 PM
Lecture: Computer Hardware and Operating Systems
Type: CS, Lecture

## Feature of Having Multiple Threads

Ease of communication:

- each thread inside the process has access to all the resources of the process
    - it allows threads to communicate without any interaction of the OS
- for processes to communication each other requires I.P.C(interprocess communication)
    - because of the segregation of each process, processes are not allowed to communication directly with each other
    - since threads exist inside of a process and they are sharing resources, one thread can talk to another thread directly
- ë§Œì•½ ì“°ë ˆë“œê°€ ì—†ë‹¤ë©´?
    - ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì›Œë“œë¥¼ ì‚¬ìš©í•  ë•Œ ê¸€ìë¥¼ íƒ€ì´í•‘í•¨ê³¼ ë™ì‹œì— ë¬¸ë²• ì˜¤ë¥˜, ì² ì ì˜¤ë¥˜, ë™ì˜ì–´ ë“±ì„ í™•ì¸í•¨
    - ë§Œì•½ ì“°ë ˆë“œê°€ ì—†ë‹¤ë©´ ë¬¸ì„œê°€ unsynchronizedë¨ â†’ ê° í”„ë¡œì„¸ìŠ¤ë§ˆë‹¤ ìƒì´í•œ ë²„ì „ì˜ ë¬¸ì„œ
        - ê·¸ë˜ì„œ ì˜ˆì „ì—ëŠ” ë¬¸ë²•ì˜¤ë¥˜, ì² ìì˜¤ë¥˜ ë“±ì˜ ê¸°ëŠ¥ë“¤ì´ ì œê³µë˜ì§€ ëª»í–ˆë˜ ê²ƒ
    - ì“°ë ˆë“œë“¤ì€ ë™ì¼í•œ ë©”ì¸ ë©”ëª¨ë¦¬ ë‚´ ë¬¸ì„œë¥¼ ìì›ìœ¼ë¡œ ê³µìœ í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥

Effective solution to prevent blocking while reading data

Threads are relatively easy to create

- all we have to do is creating a TCB(Thread Control Block) for each one
- the code is already loaded, the main memory is already there and allocated because it was for the process

**However**,

- Risk of asynchrony

## Asynchrony

Asynchrony occurs when two threads are running seemingly at the same time

E.g.

- A running thread might be interrupted due to hardware considerations, and a different thread chosen to run
- Two threads running on two different CPUs simultaneously - ì§€ê¸ˆì€ ë‹¤ìˆ˜ì˜ í”„ë¡œì„¸ì„œê°€ ì¥ì°©ë˜ì–´ ìˆìœ¼ë‹ˆê¹Œ ë™ì‹œì— ë‹¤ìˆ˜ì˜ ì“°ë ˆë“œê°€ ì‹¤í–‰ë  ìˆ˜ ìˆìŒ
    - if those two are not carefully coordinating their actions with relation to whatever it is theyâ€™re sharing then thereâ€™s gonna be very difficult problems that come up and the potential for catastrophic loss of some of the information

Because the **OS** is the one thatâ€™s deciding which thread to run, the programmer, the one designing the threads doesnâ€™t get any say in the matter of which thread to run, when to run it, and for how long

## Critical Sections

Sometimes code will be written with the expectation that once we start a particular piece of code, it will run through to completion without being interrupted

If the code is interrupted, asynchrony can occur

In a worst case scenario:

- one thread could do something to manipulate a resource partially but not completely and then stop and then another thread starts up and uses the resource from its inconsistent state assuming that it is in a consistent state and what you end up having is **corrupt data**

The programmer must identify a â€œcritical sectionâ€ of code which, once entered, must prohibit any other thread from entering a critical section on the same resource

Critical sections should be as small as possible

### Supplier / Demander

```python
bufferCount = 0;
buffer = []

def supplierThread(input):
	done = False;
	while(!done):
		if(bufferCount<500):
			bufferCount += 1
			buffer.append(input)
			done = True
		else:
			time.sleep(5)
			done = False

def demanderThread():
	done = False;
	while(!done):
		if(bufferCount>0):
			bufferCount -= 1
			temp = buffer[bufferCount]
			buffer.pop()
			return temp
		else:
			time.sleep(5)
			done = False
```

Multiple supplier and multiple demander threads are all â€œactiveâ€ in the system

- however this is a uniprocessor system so only one can run at a time

The bufferCount should NEVER exceed 500 as there are only 500 spaces to store items in the buffer

As we will see, due to asynchrony, the bufferCount can easily go higher than 500

Error scenario:

- bufferCountê°€ 499ì¸ ìˆœê°„, supplierThread()ì‹¤í–‰
    - 499ì´ê¸° ë•Œë¬¸ì— if statement ì§„ì…
    - ì´ ë•Œ interrupt ë°œìƒí•´ì„œ ë‘ë²ˆì§¸ supplierThread ì‹¤í–‰
    - ì•„ì§ bufferCountê°€ 500ì´ ë˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— if statement ì§„ì…í•´ì„œ bufferCount 500ìœ¼ë¡œ ë°”ê¾¸ê³  bufferì— 500 ì¶”ê°€
    - ë‹¤ì‹œ ì›ë˜ ì“°ë ˆë“œë¡œ ëŒì•„ì˜´ ì•„ê¹Œ left offëœ ê³³ì—ì„œ ë‹¤ì‹œ ì‹¤í–‰(thatâ€™s the concept - the programmer should not know that itâ€™s been interrupted)
    - bufferCountëŠ” 500ì´ ë˜ì—ˆì§€ë§Œ if statementì— ì´ë¯¸ ì§„ì…ë˜ì—ˆê¸° ë•Œë¬¸ì— bufferCount 501ë¡œ ë°”ê¾¸ê³  bufferì— 501 ì¶”ê°€!!ğŸ˜±

### Double Update / Missing Update

```python
balance = 0

def deposit(amount):
	newbalance = balance + amount #1
	balance = newbalance #3

def withdrawal(amount):
	newbalance = balance - amount #2
	balance = newbalance #4
```

Two transactions are happening on different processors at the exact same moment in time

Error scenario:

- the balance starts out at $100
- the first transaction is a deposit of $50, and the second transaction is a withdrawal of $100
- process
    - #1: newbalance == $150
    - (newbalanceê°€ main memoryì— ì˜¬ë¼ê°€ê¸° ì „ì—) INTERRUPT!
    - #2: newbalance == $0
    - INTERRUPT!
    - newbalanceë¥¼ main memoryì— ì˜¬ë¦¼($150)
    - #3: balance == $150 â†’ ë©€ì©¡í•´ë³´ì„!
    - newbalanceë¥¼ main memoryì— ì˜¬ë¦¼($0)
    - #4: balance == $0 â†’ ğŸ˜±ğŸ˜£ğŸ˜­ğŸ˜©ğŸ˜«ğŸ˜¡ğŸ¤¬

### Critical Sections Identified

In the Supplier/Demander example, the checking and changing of the buffer and bufferCount must be **atomic**

In the Double update/missing update problem, the entire function should be **atomic**

The need for these sections of code to be run atomically, indicates that they are critical sections

## Mutual Exclusion Rules

No two threads can be in a critical section at the same time

We have to guarantee mutual exclusion

Mutual exclusion only comes into play when weâ€™re using the same resource

- thread Aê°€ ìì› nì„ ì‚¬ìš©í•˜ëŠ” í¬ë¦¬í‹°ì»¬ ì„¹ì…˜ì— ì§„ì…í•˜ê³ , thread Bê°€ ìì› mì„ ì‚¬ìš©í•˜ëŠ” í¬ë¦¬í‹°ì»¬ ì„¹ì…˜ì— ì§„ì…í•˜ëŠ” ê²½ìš°ëŠ” í•´ë‹¹ë˜ì§€ ì•ŠìŒ

When no threads is in a critical section any threads that requests entry must be allowed in without delay

- í¬ë¦¬í‹°ì»¬ ì„¹ì…˜ì— ì§„ì…í•˜ëŠ” ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´, OSê°€ êµí†µê²½ì°° ì—­í• ì„ í•˜ê²Œ ì‹œí‚¤ëŠ” ê²ƒì€ ë‚­ë¹„ì„

A threads may remain inside a critical section only for a small amount of time

### Fundamental Mutual Exclusion

The system bus provides a fundamental system for providing mutual exclusion

Memory cannot be accessed by two processors at the same time, one will win access to the system bus and the other will have to wait until the next cycle

### Software Solutions for Mutual Exclusion

```python
flag = [False, False]
turn = 0

def P0():
	while(True):
		flag[0] = True
		turn = 1
		while (flag[1] and turn==1):
			# do nothing
		# Critical Section
		flag[0 = False

def P1():
	while(True):
		flag[1] = True
		turn = 0
		while(flag[0] and turn==0):
			# do nothing
		#Critical Section
		flag[1] = False
```

Petersonsâ€™ Algorithm provided a fundamental way to protect two threads from accessing the same resource at the same time â‡’ boolean flag!

### Hardware Solutions

Disable Interrupts

- prevent the CPU from being interrupted and you prevent asynchrony
- potentially very dangerous

Test and Set

- provide a single ML instruction to check a memory location (boolean flag) and set it if it is not set. a result is returned to indicate success or failure

Exchange

- the location in memory (maybe a flag) is swapped with a register

## Semaphores

Semaphores are a common solution programmers use to protect critical sections

![Untitled](4%20Thread%20Concurrency%20and%20Deadlocks%20028348aa90ab45099b5817320b6b0069/Untitled.png)

The OS provides some of the service, but most work is done in user space

â†’ we donâ€™t want the OS to act as a traffic cop

A semaphore is a structure which fundamental communications data structure

- Primarily two functions are used, **signal and wait**
- Signals can be queued, or, if a thread is waiting, a signal will cause it to be released
- Wait causes the thread to block if there are no signals to be consumed, the thread is queued to await the next signal

### How to Use Them

The semaphore relies on a signal being queued initially

Before entering a critical section, the thread calls wait. When exiting the thread calls signal.

Thus a semaphore will always have a signal queued when no thread is in a critical section

### Semaphore Internals

Internally semaphores usually keep some counter of the number of signals which have been sent

Wait causes the counter to decrement

If the counter ever becomes negative, the thread which caused it to go negative, and all subsequent threads, will be blocked and placed on a queue. **This is where the OS is invoked**, to perform the block.

- Up until this point, the thread itself is doing all the work

When a signal is sent, the counter is incremented and if the counter is not positive, the next thread on the queue is released

Since the act of checking and modifying the counter is a critical section, the semaphore usually uses a hardware solution to prevent asynchrony in itself

## Deadlocks - a byproduct of mutual exclusion

If a set of threads are all waiting for each other, then there is no way that any one of them will complete

![Untitled](4%20Thread%20Concurrency%20and%20Deadlocks%20028348aa90ab45099b5817320b6b0069/Untitled%201.png)

Usually this results from one thread waiting for another thread to release a resource

This is a permanent block which cannot resolve itself over time

There is no efficient solution today

### Deadlock Resource Types

Reusable

- Once the use of the resource is complete, the resource can be used again by another thread
- Examples include memory, devices, data structures, semaphores, etc
- Case
    - ë‘ ê°œì˜ í”„ë¡œì„¸ìŠ¤. í•˜ë‚˜ë„ ì ˆë°˜ ì´ìƒì˜ ë©”ì¸ë©”ëª¨ë¦¬ë¥¼ í•„ìš”ë¡œ í•˜ê³ , ë‹¤ë¥¸ í•˜ë‚˜ë„ ì ˆë°˜ ì´ìƒì˜ ë©”ì¸ë©”ëª¨ë¦¬ë¥¼ í•„ìš”ë¡œ í•¨.
    - ë‘˜ ëª¨ë‘ì—ê²Œ ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ ì œê³µë˜ì§€ ëª»í•¨

Consumable

- Once used, the resource is gone
- Examples include interrupts, signals, messages and data in IO buffers
- Case
    - if we take something out of the buffer itâ€™s not there to release the next one, weâ€™ve consumed it and itâ€™s not ever gonna go back and the next thread that comes along waiting for that resource that weâ€™ve already consumed will never be allowed to continue to run

### Items Required for a Deadlock

If we take away any one of them, the deadlock canâ€™t occur

1. Mutual Exclusion
    - Only one thread can use a resource at any given time
2. Hold-and-wait
    - While a thread is â€œwaitingâ€ on the allocation of a new resource, it retains all existing locks
3. No preemption
    - OS cannot come in and force remove resource from a thread
    - A resource cannot be removed from a thread forcefully
4. Circular wait
    - Thread A has to be waiting in some way for thread B, which is waiting again back for thread A
    - A closed chain of threads in which the **last thread is waiting on the first**
        - ultimately waiting back for itself

### Solutions for Deadlocks

Deadlock Prevention

- Eliminate one of the four requirements

Deadlock Avoidance

- Before each allocation check to make sure a deadlock is not possible, do not make an allocation that could cause a deadlock
- Required that the OS know, ahead of time, which resources a thread will request before it is finished
- Every time a thread makes a new request, the OS runs an algorithm to see if that request will cause the system to deadlock
    - if it will, the request is denied or queued
- This usually uses a â€œBankerâ€™s algorithmâ€
    - having a premonition, knowing ahead of time what a process/thread is going to request
    - if we recognize, we look at all the possible requests that could happen in the future and see if approving this request right now will cause us to not be able to complete all the other requests
    - í˜„ì¬ë¡œì„œëŠ” ì´ ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥ì— ê°€ê¹Œì›€ â†’ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ë„ ì—†ì„ ë¿ë”ëŸ¬ í•  ìˆ˜ ìˆë‹¤ê³  í•˜ë”ë¼ë„ ë„ˆë¬´ ë§ì€ CPU timeì„ ì“°ê²Œë¨

Deadlock Detection - actually what happens today the most

- Allow deadlocks to happen and then resolve it when it does
- This is not at all restrictive
- Recognize that deadlocks will occur and that a detection algorithm will need to be periodically run
- Once a deadlock is detected, the OS should take action to resolve the deadlock
- Solutions to existing deadlocks
    - rollback to a previously unlocked state (requires transaction logs)
    - abort all deadlocked threads
    - abort a thread, check for deadlock, repeat

### Dining Philosophers Problem

[https://www.youtube.com/watch?v=XjlFoND00oY](https://www.youtube.com/watch?v=XjlFoND00oY)

if all philosophers are allowed to take a chopstick(fork), all will have one chopstick and none will ever eat

Dijkstra proposed resource ordering the chopsticks

- the last philosopher had to request the zero numbered chopstick before he could request the chopstick number 4
    - youâ€™re not allowed to request the higher resource until you release the lower resource

Another solution is to have a semaphore to prevent the fifth philosopher from entering the room

- a semaphore is constructed with 4 signals queued, and the philosopher must request access to the room before requesting access to any chopstick
    - when the philosophers walk in the room each one calls **wait**
    - and the first four philosophers that call wait in order to enter the room are allowed immediate access
    - but the last one will cause that semaphore to go negative, and he will be put one a wait state outside the room
    - the first philosopher gets two chopsticks, and eat. when he finishes, he puts down the chopsticks and leaves the room.
    - the fifth philosopher enters the room